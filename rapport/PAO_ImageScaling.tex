\documentclass[12pt, a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{url}
\usepackage[usenames,dvipsnames]{color}

\usepackage[top=3.3cm, bottom=3.3cm, left=2cm, right=2cm]{geometry}

\renewcommand{\baselinestretch}{1.2}

\pagestyle{fancy}
\usepackage{lastpage}
\renewcommand\headrulewidth{1pt}
\fancyhead[L]{Image UpScaling}
\fancyhead[R]{INSA de Rouen}
\renewcommand\footrulewidth{1pt}
\fancyfoot[C]{\textbf{Page \thepage/\pageref{LastPage}}}
\fancyfoot[R]{\includegraphics[width=0.10\textwidth]{Images/Logo_INSA.png}}

\title{Rapport de projet}
\author{Ophélie Guenoux \\Olivier Petit}
\date{Janvier 2016}

\begin{document}

\makeatletter
\begin{titlepage}
  \begin{center}
      \includegraphics[width=0.20\textwidth]{Images/Logo_INSA.png}
      \hfill
      \includegraphics[width=0.25\textwidth]{Images/logoasi.png}\\
    \vspace{1cm}
		\Huge \underline{\@title} 
			\\ \textsc{Image UpScaling}
			\\ \Large Projet d'Approfondissement et d'Ouverture
			\vspace{1cm}
			\begin{figure}[h!]
				\centering
				%\includegraphics[width=0.7\textwidth]{Images/radcul.jpg}
			\end{figure}
	\vspace{1cm}
	\end{center}
	\raggedright
	\large Ophélie Guenoux \hfill Encadrant : M.Chatelain \& M.Herault
	\\Olivier Petit \hfill INSA Rouen ASI4
	
\end{titlepage}

\newpage
\tableofcontents
\newpage
\section*{Introduction}

\section{État de l'art}

\subsection{Image Scaling}
L'\textit{image scaling} est l'expression anglaise désignant les procédés informatiques liés à l'agrandissement ou la réduction de la taille d'une image.

Il existe deux familles d'image, les images vectoriels et les images matriciels. Dans le cas d'images vectoriels l'agrandissement et la réduction sont effectués par le recalcul de l'images à partir d'équations stockées dans le fichier. De cette manière nous pouvons obtenir une image lisse quelque soit le coefficient d'échelle appliqué. Ce recalcul est cependant coûteux en temps et ressources. C'est la raison pour laquelle les images matriciel sont plus répandues. Ce type d'image consiste simplement en une matrice de trois dimensions, pour la largeur, la hauteur, et les trois ou quatre canaux de couleurs. Des algorithmes de compressions permettent de faciliter le stockage mais aussi la transmission car dans le cas contraire les images peuvent être assez "lourdes".

Dans de nombreuses application les images matriciels sont préférées. Par exemple dans les anciens jeux-vidéos, les icônes, et toutes les images généralement sur internet. Là où les temps de chagement doivent être minimum.

Cependant il peut être intéressant de vouloir modifier la taille d'une image pour s'adapter par exemple aux différents types d'écrans. De plus avec l'augmentation de la résolution des écrans, certaines images doivent être très petites pour être affichées correctement. Le meilleur exemple étant la remasterisation d'anciens jeux vidéos.

\begin{figure}[h!]
  \centering
  \includegraphics[scale=0.7]{Images/tele.png}
  \caption{Upscaling x2}
\end{figure}

\subsection{Agrandissement}
 
L'augmentation de la taille d'une image revient à "créer" de nouveaux pixels qu'il faudrait remplir le mieux possible afin de garder une continuité.

L'algorithme le plus simple est celui du plus proche voisin. Il est très rapide mais fourni un résultat pixélisé 

\begin{figure}[h!]
  \centering
  \includegraphics[scale=0.6]{Images/plus_proche_voisin.png}
  \caption{Algorithme du plus proche voisin}
\end{figure}

De très nombreux algorithme existent, certain développés par de très grands laboratoires. Une liste exhaustive est diposible ici

\url{https://en.wikipedia.org/wiki/Image_scaling#Pixel_art_scaling_algorithms}

\subsection{Réduction}

La réduction d'une image est un procédé plus simple car il consiste généralement à supprimer des pixels régulièrement (par exemple un sur deux). Il n'existe pas réelement de problèmes liés à ces algorithmes car ils sont très simples à mettre en oeuvre et rapide à l'exécution.


\section{Choix de la librairie}
Pour notre projet, nous souhaitions agrandir des images avec un réseau de neurones. De ce fait, nous avons commencé à nous renseigner sur les différentes librairies. \\ Parmi elles, Pylearn2 qui nous avait été justement conseiller par nos encadrants. 
\subsection{Theano et Pylearn2}
Notre choix s'est donc orienté vers Pylearn2 une librairie opensource sous license BSD qui utilise Theano (librairie machine-learning reconnue).
\\ De plus, c'est une librairie python, langage que nous connaissions.
\\

Pylearn2 est avant tout une librairie de machine learning permettant de résoudre des problèmes de toutes sortes.(Clustering, classification, etc...)
\\De plus, la librairie implémente un ensemble de fonctions liées à la création de réseaux de neurones artificiels. Il s'agit de la classe MLP (\emph{multi layers perceptron}), qui contient toutes les types de couches connues. \\ Par exemple, dans le code suivant, nous créons un réseau de neurones contenant une couche de 75 neurones avec comme fonction d'activation une \emph{Sigmoid}
\begin{verbatim}
"model": !obj:pylearn2.models.mlp.MLP {
  "layers": [
   !obj:pylearn2.models.mlp.Sigmoid {
     layer_name: 'h1',
     dim: 75,
     irange: .5,
   },
 ]
}
\end{verbatim}
\subsection{Utilisation de \emph{YAML} avec Python}
Pylearn2 permet la définition d'un modèle de machine learning grâce à un script en \emph{YAML}.\\ L'exemple précédent est un extrait du script \emph{YAML} utilisé dans notre projet. 
\\

Initialement, pour bien comprendre le fonctionnement de la bibliothèque, nous avions réalisé une première version du projet uniquement avec des scripts Python. 
\\ Cependant, nous nous sommes très vite rendu compte des limites que cela engendrait. En effet, le code était devenu lourd et difficile à utiliser. 
\\

Par la suite, nous avons donc utilisé \emph{YAML} avec Python comme proposé par Pylearn2. Le côté architecture du réseau de neurones centralisé dans les scripts \emph{YAML} et le reste gérer par les scripts Python. 

\section{Les différentes étapes du projet}
	\subsection{Choix et construction du Dataset}
Au commencement du projet, il était question de faire un Dataset composé de chiffre allant de 0 à 9. 
Cependant, nous avons vite été confronté à un problème, sa taille. En effet, notre Dataset n'était composé que de 50 éléments, ce qui est largement insuffisant pour que l'apprentissage soit efficace.
\\ Nous avons donc décidé de changer les données utilisées en images 32 pixels par 32, noir et blanc, représentant des ellipses et des rectangles.
 
	\subsection{Utilisation de Patchs}
	% mettre des images en entier sur le réseau -> beaucoup trop lent. Du coup réduction de la taille du réseau en ne passant que les patchs
	% deux nouveaux algo pour découper l'image en patch et pour la reformer
Les images que nous utilisons sont de taille 32 par 32 pixels. Au départ nous avions pensé créer un réseau avec une entrée de dimension $32 \times 32 = 1024$ pour avoir en sortie une image agrandie $40 \times 40 = 1600$. Mais nous n'obtenions pas de résultats concluant et la taille du réseau rendant l'apprentissage très long. Nous avons donc imaginé découper les images en patchs.
\\

Après avoir soumis l'idée à nos encadrants, nous avons pris la décision de découper les images d'entrées en patchs de taille $8 \times 8$ avec un recouvrement de moitié. Pour obtenir le même nombre de patchs en entrée et en sortie, nous avons décidé de prendre des patchs de sortie de $10 \times 10$ ce qui nous fait donc une image finale de taille $40 \times 40$. L'image est reconstruite en superposant les patchs avec toujours un recouvrement de moitié et en faisant la moyenne des valeurs des pixels qui se recouvrent. 
\\

Finalement nous utilisons une fonction de seuillage pour éviter d'obtenir des valeurs inférieurs à zéro ou supérieur à 255.

	\subsection{Structure du réseau}
	% nb couche
Durant le projet nous avons essayé plusieurs architectures de réseau. Au début nous avons fait l'erreur de ne pas faire suffisamment attention à l'ensemble d'arrivé des fonctions d'activations que nous utilisions. Mais finalement nous avons obtenu une architecture satisfaisante.

	\subsubsection{Les fonctions d'activation}
	% erreur de domaine de nos données, SIgmoid prend entre -inf et +inf pour ressortir en 0 et 1 ; 
	% ajouter un shéma pour expliquer les différentes couches
Initialement nous avons choisi comme fonction d'activation sur deux couches une Sigmoid. Cependant l'ensemble de définition d'une Sigmoid est entre -inf et +inf et l'ensemble d'arrivé 0 et 1. Donc en sortie de la première couche les valeurs sont comprisent entre 0 et 1. En passant dans la seconde couche les données sont donc entre 0.5 et 1 ce qui n'est pas satisfaisant. 

\begin{figure}[h!]
  \centering
  \includegraphics[scale=0.4]{Images/sigmoid.png}
  \caption{Fonction Sigmoid}
\end{figure}

Après des recherches nous avons trouvé l'architecture suivante:
Tout d'abord une couche Sigmoid, puis RectifiedLinear et finalement GaussianLinear en couche de sortie.

\begin{figure}[h!]
  \centering
  \includegraphics[scale=1]{Images/architecture.png}
  \caption{Architecture du réseau final}
\end{figure}

\section{Problèmes rencontrés}
	\subsection{Le problème du pas}
	% Avant nous baissions tout simplement le learning rate ds une certaines fourchette d'epochs
	% tente d'utiliser un algo plus "intelligent" qui regarde 1 channel +val de sortie et par rapport à cette valeur fait augmenter ou dim le LR
	\subsection{Upscalling-RGB}
	% tentative de faire un réseau de neurones capable de faire de l'upscalling avec des images en couleur. 
	% -> problème notre image de sortie est en niveau de bleu principalement

\section*{Conclusion}
\end{document}
